<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Ml on Mayo&#39;s Blog</title>
    <link>https://mayoyamasaki.github.io/tags/ml/</link>
    <description>Recent content in Ml on Mayo&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ja</language>
    <lastBuildDate>Fri, 18 Nov 2016 00:04:32 +0900</lastBuildDate>
    <atom:link href="https://mayoyamasaki.github.io/tags/ml/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>K-Means Clustering of Word2Vec on Python</title>
      <link>https://mayoyamasaki.github.io/content/post/kmeans%20clustering%20of%20word2vec%20on%20python/</link>
      <pubDate>Fri, 18 Nov 2016 00:04:32 +0900</pubDate>
      
      <guid>https://mayoyamasaki.github.io/content/post/kmeans%20clustering%20of%20word2vec%20on%20python/</guid>
      <description>

&lt;h2 id=&#34;概要&#34;&gt;概要&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;scikit-learnのK-Means実装を使って、学習済みWord2Vecのクラスタリングを行った。&lt;/li&gt;
&lt;li&gt;それなりに上手く、クラスタリングできていそうだった。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;はじめに&#34;&gt;はじめに&lt;/h2&gt;

&lt;p&gt;ACL2014で、EmbeddingsのクラスタをNER(Named Entity Recognition)に使用している論文がある&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:1&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:1&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;。&lt;br /&gt;
線形モデルには、低次元連続値の素性(特徴量)より、高次元離散値の素性が良いらしい。&lt;br /&gt;
この記事では、Word2Vecで学習した単語ベクトル表現(連続値)を使って、K-Meansによるクラスタリング(離散値)を行ってみる。&lt;/p&gt;

&lt;h2 id=&#34;設定&#34;&gt;設定&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://code.google.com/archive/p/word2vec/&#34;&gt;Google Code word2vec&lt;/a&gt;にて公開されている、GoogleNews-vectors-negative300.bin.gzを入力に用いた。&lt;/li&gt;
&lt;li&gt;PyPIで公開されている&lt;a href=&#34;https://github.com/danielfrg/word2vec&#34;&gt;word2vec&lt;/a&gt;がTypeErrorで上手くモデルファイルをロードできなかったので、gensimの実装を使った。&lt;/li&gt;
&lt;li&gt;K-Meansには、データ量が大きかったので、scikit-learnの&lt;a href=&#34;http://scikit-learn.org/stable/modules/generated/sklearn.cluster.MiniBatchKMeans.html#sklearn.cluster.MiniBatchKMeans.fit&#34;&gt;MiniBatchKMeans&lt;/a&gt;を用いた&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:2&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:2&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;学習済みのWord2Vecのモデルファイルはいろいろ公開されていて、3Topというstartupのまとめがよかった&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:3&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:3&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;。&lt;br /&gt;
gensimのWord2Vec実装のAPIドキュメント&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:4&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:4&#34;&gt;4&lt;/a&gt;&lt;/sup&gt;は、あんまり丁寧に書かれていないので、結構つらかった。&lt;/p&gt;

&lt;h2 id=&#34;実装&#34;&gt;実装&lt;/h2&gt;
&lt;div class=&#34;highlight&#34; style=&#34;background: #f8f8f8&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;import&lt;/span&gt; &lt;span style=&#34;color: #0000FF; font-weight: bold&#34;&gt;argparse&lt;/span&gt;
&lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;from&lt;/span&gt; &lt;span style=&#34;color: #0000FF; font-weight: bold&#34;&gt;functools&lt;/span&gt; &lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;import&lt;/span&gt; lru_cache
&lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;from&lt;/span&gt; &lt;span style=&#34;color: #0000FF; font-weight: bold&#34;&gt;logging&lt;/span&gt; &lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;import&lt;/span&gt; getLogger

&lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;import&lt;/span&gt; &lt;span style=&#34;color: #0000FF; font-weight: bold&#34;&gt;numpy&lt;/span&gt; &lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;as&lt;/span&gt; &lt;span style=&#34;color: #0000FF; font-weight: bold&#34;&gt;np&lt;/span&gt;
&lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;from&lt;/span&gt; &lt;span style=&#34;color: #0000FF; font-weight: bold&#34;&gt;gensim.models.word2vec&lt;/span&gt; &lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;import&lt;/span&gt; Word2Vec
&lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;from&lt;/span&gt; &lt;span style=&#34;color: #0000FF; font-weight: bold&#34;&gt;sklearn.cluster&lt;/span&gt; &lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;import&lt;/span&gt; MiniBatchKMeans
&lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;from&lt;/span&gt; &lt;span style=&#34;color: #0000FF; font-weight: bold&#34;&gt;sklearn.externals&lt;/span&gt; &lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;import&lt;/span&gt; joblib


logger &lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt; getLogger(__name__)


&lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color: #0000FF&#34;&gt;make_dataset&lt;/span&gt;(model):
    &lt;span style=&#34;color: #BA2121; font-style: italic&#34;&gt;&amp;quot;&amp;quot;&amp;quot;Make dataset from pre-trained Word2Vec model.&lt;/span&gt;
&lt;span style=&#34;color: #BA2121; font-style: italic&#34;&gt;    Paramters&lt;/span&gt;
&lt;span style=&#34;color: #BA2121; font-style: italic&#34;&gt;    ---------&lt;/span&gt;
&lt;span style=&#34;color: #BA2121; font-style: italic&#34;&gt;    model: gensim.models.word2vec.Word2Vec&lt;/span&gt;
&lt;span style=&#34;color: #BA2121; font-style: italic&#34;&gt;        pre-traind Word2Vec model as gensim object.&lt;/span&gt;
&lt;span style=&#34;color: #BA2121; font-style: italic&#34;&gt;    Returns&lt;/span&gt;
&lt;span style=&#34;color: #BA2121; font-style: italic&#34;&gt;    -------&lt;/span&gt;
&lt;span style=&#34;color: #BA2121; font-style: italic&#34;&gt;    numpy.ndarray((vocabrary size, vector size))&lt;/span&gt;
&lt;span style=&#34;color: #BA2121; font-style: italic&#34;&gt;        Sikitlearn&amp;#39;s X format.&lt;/span&gt;
&lt;span style=&#34;color: #BA2121; font-style: italic&#34;&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    V &lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt; model&lt;span style=&#34;color: #666666&#34;&gt;.&lt;/span&gt;index2word
    X &lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color: #666666&#34;&gt;.&lt;/span&gt;zeros((&lt;span style=&#34;color: #008000&#34;&gt;len&lt;/span&gt;(V), model&lt;span style=&#34;color: #666666&#34;&gt;.&lt;/span&gt;vector_size))

    &lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;for&lt;/span&gt; index, word &lt;span style=&#34;color: #AA22FF; font-weight: bold&#34;&gt;in&lt;/span&gt; &lt;span style=&#34;color: #008000&#34;&gt;enumerate&lt;/span&gt;(V):
        X[index, :] &lt;span style=&#34;color: #666666&#34;&gt;+=&lt;/span&gt; model[word]
    &lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;return&lt;/span&gt; X


&lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color: #0000FF&#34;&gt;train&lt;/span&gt;(X, K):
    &lt;span style=&#34;color: #BA2121; font-style: italic&#34;&gt;&amp;quot;&amp;quot;&amp;quot;Learn K-Means Clustering with MiniBatchKMeans.&lt;/span&gt;
&lt;span style=&#34;color: #BA2121; font-style: italic&#34;&gt;    Paramters&lt;/span&gt;
&lt;span style=&#34;color: #BA2121; font-style: italic&#34;&gt;    ---------&lt;/span&gt;
&lt;span style=&#34;color: #BA2121; font-style: italic&#34;&gt;    X: numpy.ndarray((sample size, feature size))&lt;/span&gt;
&lt;span style=&#34;color: #BA2121; font-style: italic&#34;&gt;        training dataset.&lt;/span&gt;
&lt;span style=&#34;color: #BA2121; font-style: italic&#34;&gt;    K: int&lt;/span&gt;
&lt;span style=&#34;color: #BA2121; font-style: italic&#34;&gt;        number of clusters to use MiniBatchKMeans.&lt;/span&gt;
&lt;span style=&#34;color: #BA2121; font-style: italic&#34;&gt;    Returens&lt;/span&gt;
&lt;span style=&#34;color: #BA2121; font-style: italic&#34;&gt;    --------&lt;/span&gt;
&lt;span style=&#34;color: #BA2121; font-style: italic&#34;&gt;    sklearn.cluster.MiniBatchKMeans&lt;/span&gt;
&lt;span style=&#34;color: #BA2121; font-style: italic&#34;&gt;        trained model.&lt;/span&gt;
&lt;span style=&#34;color: #BA2121; font-style: italic&#34;&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    logger&lt;span style=&#34;color: #666666&#34;&gt;.&lt;/span&gt;info(&lt;span style=&#34;color: #BA2121&#34;&gt;&amp;#39;start to fiting KMeans with {} classs.&amp;#39;&lt;/span&gt;&lt;span style=&#34;color: #666666&#34;&gt;.&lt;/span&gt;format(K))
    classifier &lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt; MiniBatchKMeans(n_clusters&lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt;K, random_state&lt;span style=&#34;color: #666666&#34;&gt;=0&lt;/span&gt;)
    classifier&lt;span style=&#34;color: #666666&#34;&gt;.&lt;/span&gt;fit(X)
    &lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;return&lt;/span&gt; classifier


&lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color: #0000FF&#34;&gt;main&lt;/span&gt;():
    parser &lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt; argparse&lt;span style=&#34;color: #666666&#34;&gt;.&lt;/span&gt;ArgumentParser(
        description&lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #BA2121&#34;&gt;&amp;#39;Python Word2Vec Cluster&amp;#39;&lt;/span&gt;)

    parser&lt;span style=&#34;color: #666666&#34;&gt;.&lt;/span&gt;add_argument(&lt;span style=&#34;color: #BA2121&#34;&gt;&amp;#39;model&amp;#39;&lt;/span&gt;,
                        action&lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #BA2121&#34;&gt;&amp;#39;store&amp;#39;&lt;/span&gt;,
                        help&lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #BA2121&#34;&gt;&amp;#39;Name of word2vec binary modelfile.&amp;#39;&lt;/span&gt;)

    parser&lt;span style=&#34;color: #666666&#34;&gt;.&lt;/span&gt;add_argument(&lt;span style=&#34;color: #BA2121&#34;&gt;&amp;#39;-o&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color: #BA2121&#34;&gt;&amp;#39;--out&amp;#39;&lt;/span&gt;,
                        action&lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #BA2121&#34;&gt;&amp;#39;store&amp;#39;&lt;/span&gt;,
                        default&lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #BA2121&#34;&gt;&amp;#39;model.pkl&amp;#39;&lt;/span&gt;,
                        help&lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #BA2121&#34;&gt;&amp;#39;Set output filename.&amp;#39;&lt;/span&gt;)

    parser&lt;span style=&#34;color: #666666&#34;&gt;.&lt;/span&gt;add_argument(&lt;span style=&#34;color: #BA2121&#34;&gt;&amp;#39;-k&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color: #BA2121&#34;&gt;&amp;#39;--K&amp;#39;&lt;/span&gt;,
                        action&lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #BA2121&#34;&gt;&amp;#39;store&amp;#39;&lt;/span&gt;,
                        &lt;span style=&#34;color: #008000&#34;&gt;type&lt;/span&gt;&lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #008000&#34;&gt;int&lt;/span&gt;,
                        default&lt;span style=&#34;color: #666666&#34;&gt;=500&lt;/span&gt;,
                        help&lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #BA2121&#34;&gt;&amp;#39;Num of classes on KMeans.&amp;#39;&lt;/span&gt;)

    parser&lt;span style=&#34;color: #666666&#34;&gt;.&lt;/span&gt;add_argument(&lt;span style=&#34;color: #BA2121&#34;&gt;&amp;#39;-p&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color: #BA2121&#34;&gt;&amp;#39;--pre-trained-model&amp;#39;&lt;/span&gt;,
                        action&lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #BA2121&#34;&gt;&amp;#39;store&amp;#39;&lt;/span&gt;,
                        default&lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #008000&#34;&gt;None&lt;/span&gt;,
                        help&lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #BA2121&#34;&gt;&amp;#39;Use pre-trained KMeans Model.&amp;#39;&lt;/span&gt;)

    parser&lt;span style=&#34;color: #666666&#34;&gt;.&lt;/span&gt;add_argument(&lt;span style=&#34;color: #BA2121&#34;&gt;&amp;#39;-w&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color: #BA2121&#34;&gt;&amp;#39;--words-to-pred&amp;#39;&lt;/span&gt;,
                        action&lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #BA2121&#34;&gt;&amp;#39;store&amp;#39;&lt;/span&gt;,
                        nargs&lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #BA2121&#34;&gt;&amp;#39;+&amp;#39;&lt;/span&gt;,
                        &lt;span style=&#34;color: #008000&#34;&gt;type&lt;/span&gt;&lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #008000&#34;&gt;str&lt;/span&gt;,
                        default&lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #008000&#34;&gt;None&lt;/span&gt;,
                        help&lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #BA2121&#34;&gt;&amp;#39;List of word to predict.&amp;#39;&lt;/span&gt;)

    args &lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt; parser&lt;span style=&#34;color: #666666&#34;&gt;.&lt;/span&gt;parse_args()

    model &lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt; Word2Vec&lt;span style=&#34;color: #666666&#34;&gt;.&lt;/span&gt;load_word2vec_format(args&lt;span style=&#34;color: #666666&#34;&gt;.&lt;/span&gt;model, binary&lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #008000&#34;&gt;True&lt;/span&gt;)

    &lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;if&lt;/span&gt; &lt;span style=&#34;color: #AA22FF; font-weight: bold&#34;&gt;not&lt;/span&gt; args&lt;span style=&#34;color: #666666&#34;&gt;.&lt;/span&gt;pre_trained_model:
        X &lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt; make_dataset(model)
        classifier &lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt; train(X, args&lt;span style=&#34;color: #666666&#34;&gt;.&lt;/span&gt;K)
        joblib&lt;span style=&#34;color: #666666&#34;&gt;.&lt;/span&gt;dump(classifier, args&lt;span style=&#34;color: #666666&#34;&gt;.&lt;/span&gt;out)
    &lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;else&lt;/span&gt;:
        classifier &lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt; joblib&lt;span style=&#34;color: #666666&#34;&gt;.&lt;/span&gt;load(args&lt;span style=&#34;color: #666666&#34;&gt;.&lt;/span&gt;pre_trained_model)

    &lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;if&lt;/span&gt; args&lt;span style=&#34;color: #666666&#34;&gt;.&lt;/span&gt;words_to_pred:

        X &lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt; [model[word] &lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;for&lt;/span&gt; word &lt;span style=&#34;color: #AA22FF; font-weight: bold&#34;&gt;in&lt;/span&gt; args&lt;span style=&#34;color: #666666&#34;&gt;.&lt;/span&gt;words_to_pred &lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;if&lt;/span&gt; word &lt;span style=&#34;color: #AA22FF; font-weight: bold&#34;&gt;in&lt;/span&gt; model]
        classes &lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt; classifier&lt;span style=&#34;color: #666666&#34;&gt;.&lt;/span&gt;predict(X)

        result &lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt; []
        i &lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #666666&#34;&gt;0&lt;/span&gt;
        &lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;for&lt;/span&gt; word &lt;span style=&#34;color: #AA22FF; font-weight: bold&#34;&gt;in&lt;/span&gt; args&lt;span style=&#34;color: #666666&#34;&gt;.&lt;/span&gt;words_to_pred:
            &lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;if&lt;/span&gt; word &lt;span style=&#34;color: #AA22FF; font-weight: bold&#34;&gt;in&lt;/span&gt; model:
                result&lt;span style=&#34;color: #666666&#34;&gt;.&lt;/span&gt;append(&lt;span style=&#34;color: #008000&#34;&gt;str&lt;/span&gt;(classes[i]))
                i &lt;span style=&#34;color: #666666&#34;&gt;+=&lt;/span&gt; &lt;span style=&#34;color: #666666&#34;&gt;1&lt;/span&gt;
            &lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;else&lt;/span&gt;:
                result&lt;span style=&#34;color: #666666&#34;&gt;.&lt;/span&gt;append(&lt;span style=&#34;color: #008000&#34;&gt;str&lt;/span&gt;(&lt;span style=&#34;color: #666666&#34;&gt;-1&lt;/span&gt;))
        &lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color: #BA2121&#34;&gt;&amp;#39; &amp;#39;&lt;/span&gt;&lt;span style=&#34;color: #666666&#34;&gt;.&lt;/span&gt;join(result))


&lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;if&lt;/span&gt; __name__ &lt;span style=&#34;color: #666666&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color: #BA2121&#34;&gt;&amp;#39;__main__&amp;#39;&lt;/span&gt;:
    main()
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;実装は、Githubに公開している通りだが、Word2Vecの辞書をNumpyのndarrayに変換するやり方が、最適ではない気がする。まあ一度だけしか実行しないので、今回は気にしない&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:5&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:5&#34;&gt;5&lt;/a&gt;&lt;/sup&gt;。&lt;/p&gt;

&lt;h2 id=&#34;使い方&#34;&gt;使い方&lt;/h2&gt;

&lt;h3 id=&#34;学習&#34;&gt;学習&lt;/h3&gt;
&lt;div class=&#34;highlight&#34; style=&#34;background: #f8f8f8&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;$ python3 w2vcluster/w2vcluster.py GoogleNews-vectors-negative300.bin -k &lt;span style=&#34;color: #666666&#34;&gt;500&lt;/span&gt; -o model1000.pkl
&lt;/pre&gt;&lt;/div&gt;

&lt;h3 id=&#34;予測&#34;&gt;予測&lt;/h3&gt;
&lt;div class=&#34;highlight&#34; style=&#34;background: #f8f8f8&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;python3 w2vcluster/w2vcluster.py GoogleNews-vectors-negative300.bin -p model500.pkl -w apple Apple banana Google
&lt;span style=&#34;color: #666666&#34;&gt;176&lt;/span&gt; &lt;span style=&#34;color: #666666&#34;&gt;118&lt;/span&gt; &lt;span style=&#34;color: #666666&#34;&gt;176&lt;/span&gt; 118
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;argparseの可変長リストは初めて使った。見ての通り、appleとbananaはクラスタID 176に、AppleとGoogleはクラスタID 118に分類されており、上手くいっているような気がする。
モデルファイルは、joblibのpickleファイルなので、もちろんPythonからも使うことができる。やり方、READMEに一応書いている。&lt;/p&gt;

&lt;h2 id=&#34;おわりに&#34;&gt;おわりに&lt;/h2&gt;

&lt;p&gt;MiniBatchKMeansを使うと、大規模データでもMacbook Proで問題なく計算できた(数分程度で終わるが、通常のKMeansだと終わる気配がなかった&amp;hellip;)。&lt;br /&gt;
離散化したWord2Vecを何らのモデルでつかってみたい。ソフトクラスタリングも試してみたい。&lt;/p&gt;
&lt;div class=&#34;footnotes&#34;&gt;

&lt;hr /&gt;

&lt;ol&gt;
&lt;li id=&#34;fn:1&#34;&gt;&lt;a href=&#34;http://aclweb.org/anthology/D/D14/D14-1012.pdf&#34;&gt;Jiang Guo et al. Revisiting Embedding Features for Simple Semi-supervised Learning&lt;/a&gt;
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:1&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:2&#34;&gt;&lt;a href=&#34;http://scikit-learn.org/stable/auto_examples/cluster/plot_mini_batch_kmeans.html#sphx-glr-auto-examples-cluster-plot-mini-batch-kmeans-py&#34;&gt;Comparison of the K-Means and MiniBatchKMeans clustering algorithms&lt;/a&gt;
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:2&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:3&#34;&gt;&lt;a href=&#34;https://github.com/3Top/word2vec-api&#34;&gt;word2vec-api&lt;/a&gt;
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:3&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:4&#34;&gt;&lt;a href=&#34;https://radimrehurek.com/gensim/models/word2vec.html&#34;&gt;models.word2vec – Deep learning with word2vec&lt;/a&gt;
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:4&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:5&#34;&gt;&lt;a href=&#34;https://github.com/mayoyamasaki/py-kmeans-word2vec&#34;&gt;Python K-Means Cluster of Word2Vec&lt;/a&gt;
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:5&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>A Benchmark of scikit-learn SVMs</title>
      <link>https://mayoyamasaki.github.io/content/post/a-benchmark-of-scikit-learn-svm/</link>
      <pubDate>Sat, 12 Nov 2016 18:41:26 +0900</pubDate>
      
      <guid>https://mayoyamasaki.github.io/content/post/a-benchmark-of-scikit-learn-svm/</guid>
      <description>

&lt;h2 id=&#34;概要&#34;&gt;概要&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Baggingと多項式カーネルを使ったSVMが、精度と学習及び予測速度の観点で、良さそうであった。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;はじめに&#34;&gt;はじめに&lt;/h2&gt;

&lt;p&gt;あるシステムの実行速度が遅く、プロファイルしてみたところ、SVMがボトルネックになっていた。
他の処理(別の学習器も含む)と比較しても数十〜数百倍、学習と推定が遅かったので、&lt;a href=&#34;http://scikit-learn.org/stable/&#34;&gt;scikit-learn&lt;/a&gt;のSVMのベンチマークを取ってみた。&lt;/p&gt;

&lt;h2 id=&#34;設定&#34;&gt;設定&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;SVM実装は、SVC(rbf, poly), LinearSVCを使用した。&lt;/li&gt;
&lt;li&gt;OneVsRestの多クラス分類で、irisデータセットを使用した。&lt;/li&gt;
&lt;li&gt;それぞれについて、BaggingClassifierを使ったアンサンブルを試した。&lt;/li&gt;
&lt;li&gt;ついでに、RandomForestClassifierも試した。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;実装&#34;&gt;実装&lt;/h2&gt;
&lt;div class=&#34;highlight&#34; style=&#34;background: #f8f8f8&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;import&lt;/span&gt; &lt;span style=&#34;color: #0000FF; font-weight: bold&#34;&gt;time&lt;/span&gt;
&lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;from&lt;/span&gt; &lt;span style=&#34;color: #0000FF; font-weight: bold&#34;&gt;collections&lt;/span&gt; &lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;import&lt;/span&gt; defaultdict
&lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;from&lt;/span&gt; &lt;span style=&#34;color: #0000FF; font-weight: bold&#34;&gt;itertools&lt;/span&gt; &lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;import&lt;/span&gt; cycle

&lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;import&lt;/span&gt; &lt;span style=&#34;color: #0000FF; font-weight: bold&#34;&gt;matplotlib.pyplot&lt;/span&gt; &lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;as&lt;/span&gt; &lt;span style=&#34;color: #0000FF; font-weight: bold&#34;&gt;plt&lt;/span&gt;
&lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;import&lt;/span&gt; &lt;span style=&#34;color: #0000FF; font-weight: bold&#34;&gt;numpy&lt;/span&gt; &lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;as&lt;/span&gt; &lt;span style=&#34;color: #0000FF; font-weight: bold&#34;&gt;np&lt;/span&gt;
&lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;from&lt;/span&gt; &lt;span style=&#34;color: #0000FF; font-weight: bold&#34;&gt;sklearn.ensemble&lt;/span&gt; &lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;import&lt;/span&gt; BaggingClassifier
&lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;from&lt;/span&gt; &lt;span style=&#34;color: #0000FF; font-weight: bold&#34;&gt;sklearn.ensemble&lt;/span&gt; &lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;import&lt;/span&gt; RandomForestClassifier
&lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;from&lt;/span&gt; &lt;span style=&#34;color: #0000FF; font-weight: bold&#34;&gt;sklearn&lt;/span&gt; &lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;import&lt;/span&gt; datasets
&lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;from&lt;/span&gt; &lt;span style=&#34;color: #0000FF; font-weight: bold&#34;&gt;sklearn.multiclass&lt;/span&gt; &lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;import&lt;/span&gt; OneVsRestClassifier
&lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;from&lt;/span&gt; &lt;span style=&#34;color: #0000FF; font-weight: bold&#34;&gt;sklearn.svm&lt;/span&gt; &lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;import&lt;/span&gt; SVC
&lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;from&lt;/span&gt; &lt;span style=&#34;color: #0000FF; font-weight: bold&#34;&gt;sklearn.svm&lt;/span&gt; &lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;import&lt;/span&gt; LinearSVC
&lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;from&lt;/span&gt; &lt;span style=&#34;color: #0000FF; font-weight: bold&#34;&gt;sklearn.metrics&lt;/span&gt; &lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;import&lt;/span&gt; f1_score
&lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;from&lt;/span&gt; &lt;span style=&#34;color: #0000FF; font-weight: bold&#34;&gt;sklearn.model_selection&lt;/span&gt; &lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;import&lt;/span&gt; train_test_split


&lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color: #0000FF&#34;&gt;load_dataset&lt;/span&gt;():
    X, y &lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt; datasets&lt;span style=&#34;color: #666666&#34;&gt;.&lt;/span&gt;load_iris(return_X_y&lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #008000&#34;&gt;True&lt;/span&gt;)
    X &lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color: #666666&#34;&gt;.&lt;/span&gt;repeat(X, &lt;span style=&#34;color: #666666&#34;&gt;300&lt;/span&gt;, axis&lt;span style=&#34;color: #666666&#34;&gt;=0&lt;/span&gt;)
    y &lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color: #666666&#34;&gt;.&lt;/span&gt;repeat(y, &lt;span style=&#34;color: #666666&#34;&gt;300&lt;/span&gt;, axis&lt;span style=&#34;color: #666666&#34;&gt;=0&lt;/span&gt;)
    &lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;return&lt;/span&gt; X, y


&lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color: #0000FF&#34;&gt;timeit&lt;/span&gt;(func, args):
    start &lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt; time&lt;span style=&#34;color: #666666&#34;&gt;.&lt;/span&gt;clock()
    results &lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt; func(&lt;span style=&#34;color: #666666&#34;&gt;*&lt;/span&gt;args)
    end &lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt; time&lt;span style=&#34;color: #666666&#34;&gt;.&lt;/span&gt;clock()
    &lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;return&lt;/span&gt; results, end&lt;span style=&#34;color: #666666&#34;&gt;-&lt;/span&gt;start


&lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color: #0000FF&#34;&gt;make_clfs&lt;/span&gt;():
    classifiers &lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt; []
    SVCs &lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt; (
        (SVC(kernel&lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #BA2121&#34;&gt;&amp;#39;linear&amp;#39;&lt;/span&gt;), &lt;span style=&#34;color: #BA2121&#34;&gt;&amp;#39;SVC,linear&amp;#39;&lt;/span&gt;),
        (SVC(kernel&lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #BA2121&#34;&gt;&amp;#39;rbf&amp;#39;&lt;/span&gt;), &lt;span style=&#34;color: #BA2121&#34;&gt;&amp;#39;SVC,rbf&amp;#39;&lt;/span&gt;),
        (SVC(kernel&lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #BA2121&#34;&gt;&amp;#39;poly&amp;#39;&lt;/span&gt;), &lt;span style=&#34;color: #BA2121&#34;&gt;&amp;#39;SVC,poly&amp;#39;&lt;/span&gt;),
    )
    classifiers&lt;span style=&#34;color: #666666&#34;&gt;.&lt;/span&gt;extend(
        [(OneVsRestClassifier(estimater), &lt;span style=&#34;color: #BA2121&#34;&gt;&amp;#39;OvR&amp;#39;&lt;/span&gt;&lt;span style=&#34;color: #666666&#34;&gt;+&lt;/span&gt;title)
            &lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;for&lt;/span&gt; estimater,title &lt;span style=&#34;color: #AA22FF; font-weight: bold&#34;&gt;in&lt;/span&gt; SVCs])
    classifiers&lt;span style=&#34;color: #666666&#34;&gt;.&lt;/span&gt;extend(
        [(OneVsRestClassifier(
            BaggingClassifier(estimater, max_samples&lt;span style=&#34;color: #666666&#34;&gt;=0.1&lt;/span&gt;)), &lt;span style=&#34;color: #BA2121&#34;&gt;&amp;#39;OvR,Bagging,&amp;#39;&lt;/span&gt;&lt;span style=&#34;color: #666666&#34;&gt;+&lt;/span&gt;title)
                &lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;for&lt;/span&gt; estimater,title &lt;span style=&#34;color: #AA22FF; font-weight: bold&#34;&gt;in&lt;/span&gt; SVCs])
    classifiers&lt;span style=&#34;color: #666666&#34;&gt;.&lt;/span&gt;append((LinearSVC(), &lt;span style=&#34;color: #BA2121&#34;&gt;&amp;#39;LinearSVC&amp;#39;&lt;/span&gt;))
    classifiers&lt;span style=&#34;color: #666666&#34;&gt;.&lt;/span&gt;append((RandomForestClassifier(), &lt;span style=&#34;color: #BA2121&#34;&gt;&amp;#39;RandomForest&amp;#39;&lt;/span&gt;))
    &lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;return&lt;/span&gt; classifiers


&lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color: #0000FF&#34;&gt;sample&lt;/span&gt;(X, y, train_size):
    &lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;if&lt;/span&gt; train_size &lt;span style=&#34;color: #666666&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color: #666666&#34;&gt;1.&lt;/span&gt;: &lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;return&lt;/span&gt; X, y
    _X, _, _y, _  &lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt; train_test_split(X, y, train_size&lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt;train_size, random_state&lt;span style=&#34;color: #666666&#34;&gt;=0&lt;/span&gt;)
    &lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;return&lt;/span&gt; _X, _y


&lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color: #0000FF&#34;&gt;plot&lt;/span&gt;(graph_title, train_sizes, dic):
    colors &lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt; cycle([&lt;span style=&#34;color: #BA2121&#34;&gt;&amp;#39;b&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color: #BA2121&#34;&gt;&amp;#39;g&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color: #BA2121&#34;&gt;&amp;#39;r&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color: #BA2121&#34;&gt;&amp;#39;c&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color: #BA2121&#34;&gt;&amp;#39;m&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color: #BA2121&#34;&gt;&amp;#39;y&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color: #BA2121&#34;&gt;&amp;#39;k&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color: #BA2121&#34;&gt;&amp;#39;w&amp;#39;&lt;/span&gt;])
    plt&lt;span style=&#34;color: #666666&#34;&gt;.&lt;/span&gt;figure()
    plt&lt;span style=&#34;color: #666666&#34;&gt;.&lt;/span&gt;title(graph_title)
    plt&lt;span style=&#34;color: #666666&#34;&gt;.&lt;/span&gt;xlabel(&lt;span style=&#34;color: #BA2121&#34;&gt;&amp;quot;Training examples&amp;quot;&lt;/span&gt;)
    plt&lt;span style=&#34;color: #666666&#34;&gt;.&lt;/span&gt;ylabel(graph_title)
    plt&lt;span style=&#34;color: #666666&#34;&gt;.&lt;/span&gt;grid()

    &lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;for&lt;/span&gt; label, vals &lt;span style=&#34;color: #AA22FF; font-weight: bold&#34;&gt;in&lt;/span&gt; dic&lt;span style=&#34;color: #666666&#34;&gt;.&lt;/span&gt;items():
        plt&lt;span style=&#34;color: #666666&#34;&gt;.&lt;/span&gt;plot(train_sizes, vals, &lt;span style=&#34;color: #BA2121&#34;&gt;&amp;#39;o-&amp;#39;&lt;/span&gt;, color&lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #008000&#34;&gt;next&lt;/span&gt;(colors), label&lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt;label)
    plt&lt;span style=&#34;color: #666666&#34;&gt;.&lt;/span&gt;legend(loc&lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #BA2121&#34;&gt;&amp;quot;best&amp;quot;&lt;/span&gt;)
    &lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;return&lt;/span&gt; plt


&lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color: #0000FF&#34;&gt;main&lt;/span&gt;():
    CV&lt;span style=&#34;color: #666666&#34;&gt;=5&lt;/span&gt;
    X, y &lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt; load_dataset()
    classifiers &lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt; make_clfs()
    train_sizes &lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color: #666666&#34;&gt;.&lt;/span&gt;linspace(&lt;span style=&#34;color: #666666&#34;&gt;.1&lt;/span&gt;, &lt;span style=&#34;color: #666666&#34;&gt;1.&lt;/span&gt;, &lt;span style=&#34;color: #666666&#34;&gt;5&lt;/span&gt;)
    fit_times &lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt; defaultdict(&lt;span style=&#34;color: #008000&#34;&gt;list&lt;/span&gt;)
    pred_times &lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt; defaultdict(&lt;span style=&#34;color: #008000&#34;&gt;list&lt;/span&gt;)
    fscores &lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt; defaultdict(&lt;span style=&#34;color: #008000&#34;&gt;list&lt;/span&gt;)

    &lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;for&lt;/span&gt; train_size &lt;span style=&#34;color: #AA22FF; font-weight: bold&#34;&gt;in&lt;/span&gt; train_sizes:
        _X, _y &lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt; sample(X, y, train_size)
        &lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;for&lt;/span&gt; clf, title &lt;span style=&#34;color: #AA22FF; font-weight: bold&#34;&gt;in&lt;/span&gt; classifiers:
            scores &lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt; {&lt;span style=&#34;color: #BA2121&#34;&gt;&amp;#39;fit&amp;#39;&lt;/span&gt;:[], &lt;span style=&#34;color: #BA2121&#34;&gt;&amp;#39;pred&amp;#39;&lt;/span&gt;:[], &lt;span style=&#34;color: #BA2121&#34;&gt;&amp;#39;fscore&amp;#39;&lt;/span&gt;:[] }
            &lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;for&lt;/span&gt; n_cv &lt;span style=&#34;color: #AA22FF; font-weight: bold&#34;&gt;in&lt;/span&gt; &lt;span style=&#34;color: #008000&#34;&gt;range&lt;/span&gt;(CV):
                X_train, X_test, y_train, y_test &lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt; train_test_split(
                    _X, _y, test_size&lt;span style=&#34;color: #666666&#34;&gt;=0.4&lt;/span&gt;, random_state&lt;span style=&#34;color: #666666&#34;&gt;=0&lt;/span&gt;)

                _, t &lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt; timeit(clf&lt;span style=&#34;color: #666666&#34;&gt;.&lt;/span&gt;fit, (X_train, y_train))
                scores[&lt;span style=&#34;color: #BA2121&#34;&gt;&amp;#39;fit&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color: #666666&#34;&gt;.&lt;/span&gt;append(t)

                y_pred, t &lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt; timeit(clf&lt;span style=&#34;color: #666666&#34;&gt;.&lt;/span&gt;predict, (X_test, ))
                scores[&lt;span style=&#34;color: #BA2121&#34;&gt;&amp;#39;pred&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color: #666666&#34;&gt;.&lt;/span&gt;append(t)

                fscore &lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt; f1_score(y_test, y_pred, average&lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #BA2121&#34;&gt;&amp;#39;macro&amp;#39;&lt;/span&gt;)
                scores[&lt;span style=&#34;color: #BA2121&#34;&gt;&amp;#39;fscore&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color: #666666&#34;&gt;.&lt;/span&gt;append(fscore)

            fit_times[title]&lt;span style=&#34;color: #666666&#34;&gt;.&lt;/span&gt;append(np&lt;span style=&#34;color: #666666&#34;&gt;.&lt;/span&gt;mean(scores[&lt;span style=&#34;color: #BA2121&#34;&gt;&amp;#39;fit&amp;#39;&lt;/span&gt;]))
            pred_times[title]&lt;span style=&#34;color: #666666&#34;&gt;.&lt;/span&gt;append(np&lt;span style=&#34;color: #666666&#34;&gt;.&lt;/span&gt;mean(scores[&lt;span style=&#34;color: #BA2121&#34;&gt;&amp;#39;pred&amp;#39;&lt;/span&gt;]))
            fscores[title]&lt;span style=&#34;color: #666666&#34;&gt;.&lt;/span&gt;append(np&lt;span style=&#34;color: #666666&#34;&gt;.&lt;/span&gt;mean(scores[&lt;span style=&#34;color: #BA2121&#34;&gt;&amp;#39;fscore&amp;#39;&lt;/span&gt;]))

    plot(&lt;span style=&#34;color: #BA2121&#34;&gt;&amp;#39;Fscores&amp;#39;&lt;/span&gt;, train_sizes, fscores)
    plot(&lt;span style=&#34;color: #BA2121&#34;&gt;&amp;#39;Time of Training&amp;#39;&lt;/span&gt;, train_sizes, fit_times)
    plot(&lt;span style=&#34;color: #BA2121&#34;&gt;&amp;#39;Time of Predication&amp;#39;&lt;/span&gt;, train_sizes, pred_times)
    plt&lt;span style=&#34;color: #666666&#34;&gt;.&lt;/span&gt;show()


&lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;if&lt;/span&gt; __name__ &lt;span style=&#34;color: #666666&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color: #BA2121&#34;&gt;&amp;#39;__main__&amp;#39;&lt;/span&gt;:
    main()
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;code&gt;make_clfs&lt;/code&gt;で作成した分類器一つ一つに対して、学習時間、推測時間、F値(マクロ平均)を求めている。
尚、これらの値は5回施行の平均値であり、データ量増加に対する、推移を見ている。&lt;/p&gt;

&lt;h2 id=&#34;結果&#34;&gt;結果&lt;/h2&gt;

&lt;h3 id=&#34;f値&#34;&gt;F値&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://mayoyamasaki.github.io/images/a-benchmark-of-scikit-learn-svm/fscores.png&#34; alt=&#34;fscores&#34; /&gt;&lt;/p&gt;

&lt;p&gt;一瞬見失うが、RandomForestの精度が最も高く、非線形カーネル、線形カーネルの順番に精度が高かった。
また、Baggingを加えても非線形カーネルではほとんど差が出ていない。&lt;/p&gt;

&lt;h3 id=&#34;学習時間&#34;&gt;学習時間&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://mayoyamasaki.github.io/images/a-benchmark-of-scikit-learn-svm/trains.png&#34; alt=&#34;trains&#34; /&gt;
多項式カーネルでは、Baggingの効果が顕著にでている。また、SVCの線形カーネルは話に聞く通り低パフォーマンスで、LinearSVCの方が学習時間は少ない。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;単位記述を忘れたが、縦軸は[s]である。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&#34;予測時間&#34;&gt;予測時間&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://mayoyamasaki.github.io/images/a-benchmark-of-scikit-learn-svm/preds.png&#34; alt=&#34;preds&#34; /&gt;
予測時間では、一転してBaggingを使用しない方が速度がでている傾向にある。また、推測においてもSVCの線形カーネルのパフォーマンスは低い。&lt;/p&gt;

&lt;h2 id=&#34;おわりに&#34;&gt;おわりに&lt;/h2&gt;

&lt;p&gt;この手のベンチマークはデータセットに依存するが、今回の評価では、SVMの中では、Baggingを使った多項式カーネルによるOneVsRestが有効であった。&lt;br /&gt;
今回の様に汎化しやすそうなデータセットでは、やはりRandomForestは有効で、今後は、多様なデータセットでの検証をやってみたい。&lt;br /&gt;
また、Baggingやアンサンブル学習を初めて試してみたが、実行速度改善に大きく寄与したので、実システムでも試してみたい。尚、Baggingについは、アンサンブル学習のスライドが分かりやすかった&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:1&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:1&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;。&lt;/p&gt;
&lt;div class=&#34;footnotes&#34;&gt;

&lt;hr /&gt;

&lt;ol&gt;
&lt;li id=&#34;fn:1&#34;&gt;&lt;a href=&#34;http://www.slideshare.net/holidayworking/ss-11948523&#34;&gt;アンサンブル学習&lt;/a&gt;
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:1&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>