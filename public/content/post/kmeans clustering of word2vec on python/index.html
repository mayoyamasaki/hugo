
<!DOCTYPE html>
<html lang="ja">
<head>

  
  <meta charset="UTF-8">
  <title>
    K-Means Clustering of Word2Vec on Python | Mayo&#39;s Blog
  </title>


  
  <meta name="viewport" content="width=device-width,user-scalable=no,maximum-scale=1,initial-scale=1">

  
  <link rel="canonical" href="https://mayoyamasaki.github.io/content/post/kmeans%20clustering%20of%20word2vec%20on%20python/"/>

  
  <link rel="stylesheet" href="/css/sanitize.css">
  <link rel="stylesheet" href="/css/responsive.css">
  <link rel="stylesheet" href="/css/highlight_monokai.css">
  <link rel="stylesheet" href="/css/theme.css">
  <link rel="stylesheet" href="/css/custom.css">
  
  
  <link href="https://mayoyamasaki.github.io/index.xml" rel="alternate" type="application/rss+xml" title="Mayo&#39;s Blog" />
  <link href="https://mayoyamasaki.github.io/index.xml" rel="feed" type="application/rss+xml" title="Mayo&#39;s Blog" />

  
  


</head>



<body>
<div class="container">

  
  <header role="banner">
    <div class="row gutters">
      <div id="site-title" class="col span_6">
        <h1><a href="https://mayoyamasaki.github.io/">Mayo&#39;s Blog</a></h1>
        
      </div>
      <div id="social" class="col span_6">
        <ul>
          <li><a href="https://twitter.com/mayoyamasaki" target="_blank">Twitter</a></li>
          
          <li><a href="https://github.com/mayoyamasaki" target="_blank">GitHub</a></li>
          <li><a href="https://mayoyamasaki.github.io/index.xml" type="application/rss+xml" target="_blank">RSS</a></li>
        </ul>
      </div>
    </div>
  </header>


  
  <main id="single" role="main">
    <div class="article-header">
      <h1>K-Means Clustering of Word2Vec on Python</h1>
      <div class="meta">
        Nov 18, 2016 &nbsp;
        
          #<a href="/tags/ml">ML</a>&nbsp;
        
          #<a href="/tags/nlp">NLP</a>&nbsp;
        
          #<a href="/tags/python">Python</a>&nbsp;
        
      </div>
    </div>
    <article>
      

<h2 id="概要">概要</h2>

<ul>
<li>scikit-learnのK-Means実装を使って、学習済みWord2Vecのクラスタリングを行った。</li>
<li>それなりに上手く、クラスタリングできていそうだった。</li>
</ul>

<h2 id="はじめに">はじめに</h2>

<p>ACL2014で、EmbeddingsのクラスタをNER(Named Entity Recognition)に使用している論文がある<sup class="footnote-ref" id="fnref:1"><a rel="footnote" href="#fn:1">1</a></sup>。<br />
線形モデルには、低次元連続値の素性(特徴量)より、高次元離散値の素性が良いらしい。<br />
この記事では、Word2Vecで学習した単語ベクトル表現(連続値)を使って、K-Meansによるクラスタリング(離散値)を行ってみる。</p>

<h2 id="設定">設定</h2>

<ul>
<li><a href="https://code.google.com/archive/p/word2vec/">Google Code word2vec</a>にて公開されている、GoogleNews-vectors-negative300.bin.gzを入力に用いた。</li>
<li>PyPIで公開されている<a href="https://github.com/danielfrg/word2vec">word2vec</a>がTypeErrorで上手くモデルファイルをロードできなかったので、gensimの実装を使った。</li>
<li>K-Meansには、データ量が大きかったので、scikit-learnの<a href="http://scikit-learn.org/stable/modules/generated/sklearn.cluster.MiniBatchKMeans.html#sklearn.cluster.MiniBatchKMeans.fit">MiniBatchKMeans</a>を用いた<sup class="footnote-ref" id="fnref:2"><a rel="footnote" href="#fn:2">2</a></sup>。</li>
</ul>

<p>学習済みのWord2Vecのモデルファイルはいろいろ公開されていて、3Topというstartupのまとめがよかった<sup class="footnote-ref" id="fnref:3"><a rel="footnote" href="#fn:3">3</a></sup>。<br />
gensimのWord2Vec実装のAPIドキュメント<sup class="footnote-ref" id="fnref:4"><a rel="footnote" href="#fn:4">4</a></sup>は、あんまり丁寧に書かれていないので、結構つらかった。</p>

<h2 id="実装">実装</h2>
<div class="highlight" style="background: #f8f8f8"><pre style="line-height: 125%"><span></span><span style="color: #008000; font-weight: bold">import</span> <span style="color: #0000FF; font-weight: bold">argparse</span>
<span style="color: #008000; font-weight: bold">from</span> <span style="color: #0000FF; font-weight: bold">functools</span> <span style="color: #008000; font-weight: bold">import</span> lru_cache
<span style="color: #008000; font-weight: bold">from</span> <span style="color: #0000FF; font-weight: bold">logging</span> <span style="color: #008000; font-weight: bold">import</span> getLogger

<span style="color: #008000; font-weight: bold">import</span> <span style="color: #0000FF; font-weight: bold">numpy</span> <span style="color: #008000; font-weight: bold">as</span> <span style="color: #0000FF; font-weight: bold">np</span>
<span style="color: #008000; font-weight: bold">from</span> <span style="color: #0000FF; font-weight: bold">gensim.models.word2vec</span> <span style="color: #008000; font-weight: bold">import</span> Word2Vec
<span style="color: #008000; font-weight: bold">from</span> <span style="color: #0000FF; font-weight: bold">sklearn.cluster</span> <span style="color: #008000; font-weight: bold">import</span> MiniBatchKMeans
<span style="color: #008000; font-weight: bold">from</span> <span style="color: #0000FF; font-weight: bold">sklearn.externals</span> <span style="color: #008000; font-weight: bold">import</span> joblib


logger <span style="color: #666666">=</span> getLogger(__name__)


<span style="color: #008000; font-weight: bold">def</span> <span style="color: #0000FF">make_dataset</span>(model):
    <span style="color: #BA2121; font-style: italic">&quot;&quot;&quot;Make dataset from pre-trained Word2Vec model.</span>
<span style="color: #BA2121; font-style: italic">    Paramters</span>
<span style="color: #BA2121; font-style: italic">    ---------</span>
<span style="color: #BA2121; font-style: italic">    model: gensim.models.word2vec.Word2Vec</span>
<span style="color: #BA2121; font-style: italic">        pre-traind Word2Vec model as gensim object.</span>
<span style="color: #BA2121; font-style: italic">    Returns</span>
<span style="color: #BA2121; font-style: italic">    -------</span>
<span style="color: #BA2121; font-style: italic">    numpy.ndarray((vocabrary size, vector size))</span>
<span style="color: #BA2121; font-style: italic">        Sikitlearn&#39;s X format.</span>
<span style="color: #BA2121; font-style: italic">    &quot;&quot;&quot;</span>
    V <span style="color: #666666">=</span> model<span style="color: #666666">.</span>index2word
    X <span style="color: #666666">=</span> np<span style="color: #666666">.</span>zeros((<span style="color: #008000">len</span>(V), model<span style="color: #666666">.</span>vector_size))

    <span style="color: #008000; font-weight: bold">for</span> index, word <span style="color: #AA22FF; font-weight: bold">in</span> <span style="color: #008000">enumerate</span>(V):
        X[index, :] <span style="color: #666666">+=</span> model[word]
    <span style="color: #008000; font-weight: bold">return</span> X


<span style="color: #008000; font-weight: bold">def</span> <span style="color: #0000FF">train</span>(X, K):
    <span style="color: #BA2121; font-style: italic">&quot;&quot;&quot;Learn K-Means Clustering with MiniBatchKMeans.</span>
<span style="color: #BA2121; font-style: italic">    Paramters</span>
<span style="color: #BA2121; font-style: italic">    ---------</span>
<span style="color: #BA2121; font-style: italic">    X: numpy.ndarray((sample size, feature size))</span>
<span style="color: #BA2121; font-style: italic">        training dataset.</span>
<span style="color: #BA2121; font-style: italic">    K: int</span>
<span style="color: #BA2121; font-style: italic">        number of clusters to use MiniBatchKMeans.</span>
<span style="color: #BA2121; font-style: italic">    Returens</span>
<span style="color: #BA2121; font-style: italic">    --------</span>
<span style="color: #BA2121; font-style: italic">    sklearn.cluster.MiniBatchKMeans</span>
<span style="color: #BA2121; font-style: italic">        trained model.</span>
<span style="color: #BA2121; font-style: italic">    &quot;&quot;&quot;</span>
    logger<span style="color: #666666">.</span>info(<span style="color: #BA2121">&#39;start to fiting KMeans with {} classs.&#39;</span><span style="color: #666666">.</span>format(K))
    classifier <span style="color: #666666">=</span> MiniBatchKMeans(n_clusters<span style="color: #666666">=</span>K, random_state<span style="color: #666666">=0</span>)
    classifier<span style="color: #666666">.</span>fit(X)
    <span style="color: #008000; font-weight: bold">return</span> classifier


<span style="color: #008000; font-weight: bold">def</span> <span style="color: #0000FF">main</span>():
    parser <span style="color: #666666">=</span> argparse<span style="color: #666666">.</span>ArgumentParser(
        description<span style="color: #666666">=</span><span style="color: #BA2121">&#39;Python Word2Vec Cluster&#39;</span>)

    parser<span style="color: #666666">.</span>add_argument(<span style="color: #BA2121">&#39;model&#39;</span>,
                        action<span style="color: #666666">=</span><span style="color: #BA2121">&#39;store&#39;</span>,
                        help<span style="color: #666666">=</span><span style="color: #BA2121">&#39;Name of word2vec binary modelfile.&#39;</span>)

    parser<span style="color: #666666">.</span>add_argument(<span style="color: #BA2121">&#39;-o&#39;</span>, <span style="color: #BA2121">&#39;--out&#39;</span>,
                        action<span style="color: #666666">=</span><span style="color: #BA2121">&#39;store&#39;</span>,
                        default<span style="color: #666666">=</span><span style="color: #BA2121">&#39;model.pkl&#39;</span>,
                        help<span style="color: #666666">=</span><span style="color: #BA2121">&#39;Set output filename.&#39;</span>)

    parser<span style="color: #666666">.</span>add_argument(<span style="color: #BA2121">&#39;-k&#39;</span>, <span style="color: #BA2121">&#39;--K&#39;</span>,
                        action<span style="color: #666666">=</span><span style="color: #BA2121">&#39;store&#39;</span>,
                        <span style="color: #008000">type</span><span style="color: #666666">=</span><span style="color: #008000">int</span>,
                        default<span style="color: #666666">=500</span>,
                        help<span style="color: #666666">=</span><span style="color: #BA2121">&#39;Num of classes on KMeans.&#39;</span>)

    parser<span style="color: #666666">.</span>add_argument(<span style="color: #BA2121">&#39;-p&#39;</span>, <span style="color: #BA2121">&#39;--pre-trained-model&#39;</span>,
                        action<span style="color: #666666">=</span><span style="color: #BA2121">&#39;store&#39;</span>,
                        default<span style="color: #666666">=</span><span style="color: #008000">None</span>,
                        help<span style="color: #666666">=</span><span style="color: #BA2121">&#39;Use pre-trained KMeans Model.&#39;</span>)

    parser<span style="color: #666666">.</span>add_argument(<span style="color: #BA2121">&#39;-w&#39;</span>, <span style="color: #BA2121">&#39;--words-to-pred&#39;</span>,
                        action<span style="color: #666666">=</span><span style="color: #BA2121">&#39;store&#39;</span>,
                        nargs<span style="color: #666666">=</span><span style="color: #BA2121">&#39;+&#39;</span>,
                        <span style="color: #008000">type</span><span style="color: #666666">=</span><span style="color: #008000">str</span>,
                        default<span style="color: #666666">=</span><span style="color: #008000">None</span>,
                        help<span style="color: #666666">=</span><span style="color: #BA2121">&#39;List of word to predict.&#39;</span>)

    args <span style="color: #666666">=</span> parser<span style="color: #666666">.</span>parse_args()

    model <span style="color: #666666">=</span> Word2Vec<span style="color: #666666">.</span>load_word2vec_format(args<span style="color: #666666">.</span>model, binary<span style="color: #666666">=</span><span style="color: #008000">True</span>)

    <span style="color: #008000; font-weight: bold">if</span> <span style="color: #AA22FF; font-weight: bold">not</span> args<span style="color: #666666">.</span>pre_trained_model:
        X <span style="color: #666666">=</span> make_dataset(model)
        classifier <span style="color: #666666">=</span> train(X, args<span style="color: #666666">.</span>K)
        joblib<span style="color: #666666">.</span>dump(classifier, args<span style="color: #666666">.</span>out)
    <span style="color: #008000; font-weight: bold">else</span>:
        classifier <span style="color: #666666">=</span> joblib<span style="color: #666666">.</span>load(args<span style="color: #666666">.</span>pre_trained_model)

    <span style="color: #008000; font-weight: bold">if</span> args<span style="color: #666666">.</span>words_to_pred:

        X <span style="color: #666666">=</span> [model[word] <span style="color: #008000; font-weight: bold">for</span> word <span style="color: #AA22FF; font-weight: bold">in</span> args<span style="color: #666666">.</span>words_to_pred <span style="color: #008000; font-weight: bold">if</span> word <span style="color: #AA22FF; font-weight: bold">in</span> model]
        classes <span style="color: #666666">=</span> classifier<span style="color: #666666">.</span>predict(X)

        result <span style="color: #666666">=</span> []
        i <span style="color: #666666">=</span> <span style="color: #666666">0</span>
        <span style="color: #008000; font-weight: bold">for</span> word <span style="color: #AA22FF; font-weight: bold">in</span> args<span style="color: #666666">.</span>words_to_pred:
            <span style="color: #008000; font-weight: bold">if</span> word <span style="color: #AA22FF; font-weight: bold">in</span> model:
                result<span style="color: #666666">.</span>append(<span style="color: #008000">str</span>(classes[i]))
                i <span style="color: #666666">+=</span> <span style="color: #666666">1</span>
            <span style="color: #008000; font-weight: bold">else</span>:
                result<span style="color: #666666">.</span>append(<span style="color: #008000">str</span>(<span style="color: #666666">-1</span>))
        <span style="color: #008000; font-weight: bold">print</span>(<span style="color: #BA2121">&#39; &#39;</span><span style="color: #666666">.</span>join(result))


<span style="color: #008000; font-weight: bold">if</span> __name__ <span style="color: #666666">==</span> <span style="color: #BA2121">&#39;__main__&#39;</span>:
    main()
</pre></div>

<p>実装は、Githubに公開している通りだが、Word2Vecの辞書をNumpyのndarrayに変換するやり方が、最適ではない気がする。まあ一度だけしか実行しないので、今回は気にしない<sup class="footnote-ref" id="fnref:5"><a rel="footnote" href="#fn:5">5</a></sup>。</p>

<h2 id="使い方">使い方</h2>

<h3 id="学習">学習</h3>
<div class="highlight" style="background: #f8f8f8"><pre style="line-height: 125%"><span></span>$ python3 w2vcluster/w2vcluster.py GoogleNews-vectors-negative300.bin -k <span style="color: #666666">500</span> -o model1000.pkl
</pre></div>

<h3 id="予測">予測</h3>
<div class="highlight" style="background: #f8f8f8"><pre style="line-height: 125%"><span></span>python3 w2vcluster/w2vcluster.py GoogleNews-vectors-negative300.bin -p model500.pkl -w apple Apple banana Google
<span style="color: #666666">176</span> <span style="color: #666666">118</span> <span style="color: #666666">176</span> 118
</pre></div>

<p>argparseの可変長リストは初めて使った。見ての通り、appleとbananaはクラスタID 176に、AppleとGoogleはクラスタID 118に分類されており、上手くいっているような気がする。
モデルファイルは、joblibのpickleファイルなので、もちろんPythonからも使うことができる。やり方、READMEに一応書いている。</p>

<h2 id="おわりに">おわりに</h2>

<p>MiniBatchKMeansを使うと、大規模データでもMacbook Proで問題なく計算できた(数分程度で終わるが、通常のKMeansだと終わる気配がなかった&hellip;)。<br />
離散化したWord2Vecを何らのモデルでつかってみたい。ソフトクラスタリングも試してみたい。</p>
<div class="footnotes">

<hr />

<ol>
<li id="fn:1"><a href="http://aclweb.org/anthology/D/D14/D14-1012.pdf">Jiang Guo et al. Revisiting Embedding Features for Simple Semi-supervised Learning</a>
 <a class="footnote-return" href="#fnref:1"><sup>[return]</sup></a></li>
<li id="fn:2"><a href="http://scikit-learn.org/stable/auto_examples/cluster/plot_mini_batch_kmeans.html#sphx-glr-auto-examples-cluster-plot-mini-batch-kmeans-py">Comparison of the K-Means and MiniBatchKMeans clustering algorithms</a>
 <a class="footnote-return" href="#fnref:2"><sup>[return]</sup></a></li>
<li id="fn:3"><a href="https://github.com/3Top/word2vec-api">word2vec-api</a>
 <a class="footnote-return" href="#fnref:3"><sup>[return]</sup></a></li>
<li id="fn:4"><a href="https://radimrehurek.com/gensim/models/word2vec.html">models.word2vec – Deep learning with word2vec</a>
 <a class="footnote-return" href="#fnref:4"><sup>[return]</sup></a></li>
<li id="fn:5"><a href="https://github.com/mayoyamasaki/py-kmeans-word2vec">Python K-Means Cluster of Word2Vec</a>
 <a class="footnote-return" href="#fnref:5"><sup>[return]</sup></a></li>
</ol>
</div>

      
      
      
    </article>
    
 <aside><div id="disqus_thread"></div></aside>

<script type="text/javascript">
     
    var disqus_shortname = 'mayoyamasaki';

     
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>



  </main>
  
  <nav class="pagination-single">
    
      <span class="previous">&larr; <a href="https://mayoyamasaki.github.io/content/post/introduction-to-neo4j/" rel="prev">Introduction to Neo4j</a></span>
    
    
  </nav>


  
  <footer role="contentinfo">
    <div style="text-align:center;">
      
      Copyright (c) 2016, mayo yamasaki all rights reserved.
    </div>
  </footer>


</div>

<script src="/js/highlight.pack.js"></script>
<script>hljs.initHighlightingOnLoad();</script>



</body>
</html>

